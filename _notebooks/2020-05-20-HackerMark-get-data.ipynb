{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Part 1: Getting data from HackerNews\"\n",
    "> \"Here I will describe the process that I used to get HN data.\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Pushkar Paranjpe\n",
    "- categories: [HN, google, chrome, extension, unsupervised, ML]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where is the data ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had two options - either download the news data from HN using their [API](https://github.com/HackerNews/API) or get a (near) up-to-date dump via [Kaggle](https://www.kaggle.com/hacker-news/hacker-news). Yes! Kaggle is not just for getting into the world of competitive ML coding. It is a fabulous resource for a broad variety of structured datasets.\n",
    "Here is the link for - [HN data](https://www.kaggle.com/hacker-news/hacker-news)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/kaggle_hn_data.png \"Kaggle is for data too!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The header image says it has posts from 2006 to late 2017. But if you look inside the data tables you will find that it has data upto the current week. Current day and up to a couple previous days may not be in it. You will have to use the HN API to get that - but more on that later. For now all the HN data upto current minus two days will suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Google's BigQuery to access the data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write some SQL queries to explore the data, save it to the Kaggle's working directory. You get a (generous) 5GB of space in your working directory! That's where I will put HN data. Later, I will show you a nifty trick to download that data to your data processing machine. \n",
    "\n",
    "First - fire up a Kaggle notebook. Start coding!\n",
    "\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "```\n",
    "\n",
    "Our SQL client is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets's explore the HN dataset a bit.\n",
    "\n",
    "\n",
    "```python\n",
    "query = \"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM\n",
    "        bigquery-public-data.hacker_news.full\n",
    "        WHERE\n",
    "          type = 'story'\n",
    "          AND\n",
    "          title IS NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "# Set up the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "query_job.to_dataframe()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Output:\n",
    "\n",
    "\n",
    "|   | f0_ |\n",
    "| - | - |\n",
    "| 0  |\t3524454 |\n",
    " \n",
    "\n",
    "So - there are about 3M rows of the type 'story' that have a non-empty title. Why do we care about the `title` ? Well - we will be using the title field alone to build the news catalogue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some rows.\n",
    "\n",
    "\n",
    "```python\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM\n",
    "        bigquery-public-data.hacker_news.full\n",
    "        WHERE type = 'story'\n",
    "        LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# Set up the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "query_job.to_dataframe()\n",
    "```\n",
    "\n",
    "![](./images/hn_stories_rows.png \"Sample rows from the HN table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the lastest row in this table ? Lets find out!\n",
    "\n",
    "```python\n",
    "query = \"\"\"\n",
    "        SELECT MAX(timestamp)\n",
    "        FROM\n",
    "        bigquery-public-data.hacker_news.full\n",
    "        WHERE type = 'story'\n",
    "        AND DATE(timestamp) > '2020-05-01';\n",
    "\"\"\"\n",
    "\n",
    "# Set up the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "query_job.to_dataframe()\n",
    "```\n",
    "\n",
    "I ran the query on `2020-05-20 9:30 p.m. IST`. Here was the output:\n",
    "\n",
    "| | f0_|\n",
    "| - | - |\n",
    "|0\t| 2020-05-19 11:19:42+00:00|\n",
    "\n",
    "So - less than a day old. Not bad for a data source that is freely available and maintained by a 3rd party (not me, laziness !)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fetch the data now.\n",
    "\n",
    "```python\n",
    "query = \"\"\"\n",
    "        SELECT title, id, timestamp\n",
    "        FROM\n",
    "        bigquery-public-data.hacker_news.full\n",
    "        WHERE\n",
    "                type = 'story'\n",
    "            AND title IS NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "# Set up the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "df_stories = query_job.to_dataframe()\n",
    "\n",
    "df_stories.shape\n",
    "```\n",
    "\n",
    "This query will run for a little longer but no longer than 10 minutes. Remember, we are getting *all* the HN stories that have a title and there are about 3M of them at time of this writing. Patience !\n",
    "\n",
    "Here's the output:  \n",
    "`(3524454, 3)`\n",
    "\n",
    "Naice (: We've got > 3.5 million stories to play with ! And for each of them we have - a HN id, a timestamp and a title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our hard work locally i.e. inside the Kaggle working directory.\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open('hn.stories.dt.pickle', 'wb') as outf:\n",
    "    pickle.dump(df_stories, outf)\n",
    "```\n",
    "\n",
    "Check our work:  \n",
    "`!ls -al --block-size=M *.pickle`\n",
    "\n",
    "Output:  \n",
    "`-rw-r--r-- 1 root root 250M May 20 16:10 hn.stories.dt.pickle`\n",
    "\n",
    "Thats good. Sweet 250 mega bytes of HN news data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A nifty little trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a nifty trick that I had promised - to create a cute little download link! \n",
    "\n",
    "```python\n",
    "from IPython.display import FileLink\n",
    "\n",
    "\n",
    "FileLink(r'hn.stories.dt.pickle')\n",
    "```\n",
    "\n",
    "Output:  \n",
    "[hn.stories.dt.pickle](hn.stories.dt.pickle)\n",
    "\n",
    "The output is a hyperlink to your pickle file. Use `wget` or your favorite download manager to get that file onto your data processing machine. I have used an AWS EC2 instance for further work. So lets say bye to Kaggle and hello to EC2. See you there - in the [next blog post](https://pushkarparanjpe.github.io/kidepaha_fastpages/hn/google/chrome/extension/unsupervised/ml/2020/05/24/HackerMark-featurise-titles.html) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
